{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#TODO: improve the sentiment classifier\n#TODO: save the sentiment classifier to save time\n#TODO: save the ngrams to save time\n#TODO: explore the good and bad examples","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":5,"outputs":[{"output_type":"stream","text":"/kaggle/input/tweet-sentiment-extraction/train.csv\n/kaggle/input/tweet-sentiment-extraction/test.csv\n/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_data = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")\ndf_sample_submission = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\")\nprint(\"df_data shape\", df_data.shape,\"\\n\", \"df_test shape\", df_test.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"df_data shape (27486, 4) \n df_test shape (3535, 3)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data = df_data[~df_data.text.isnull()]\ndf_data.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"       textID                                               text  \\\n0  a3d0a7d5ad  Spent the entire morning in a meeting w/ a ven...   \n1  251b6a6766      Oh! Good idea about putting them on ice cream   \n2  c9e8d1ef1c  says good (or should i say bad?) afternoon!  h...   \n3  f14f087215         i dont think you can vote anymore! i tried   \n4  bf7473b12d             haha better drunken tweeting you mean?   \n\n                                 selected_text sentiment  \n0  my boss was not happy w/ them. Lots of fun.   neutral  \n1                                         Good  positive  \n2  says good (or should i say bad?) afternoon!   neutral  \n3           i dont think you can vote anymore!  negative  \n4                                       better  positive  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a3d0a7d5ad</td>\n      <td>Spent the entire morning in a meeting w/ a ven...</td>\n      <td>my boss was not happy w/ them. Lots of fun.</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>251b6a6766</td>\n      <td>Oh! Good idea about putting them on ice cream</td>\n      <td>Good</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c9e8d1ef1c</td>\n      <td>says good (or should i say bad?) afternoon!  h...</td>\n      <td>says good (or should i say bad?) afternoon!</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>f14f087215</td>\n      <td>i dont think you can vote anymore! i tried</td>\n      <td>i dont think you can vote anymore!</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bf7473b12d</td>\n      <td>haha better drunken tweeting you mean?</td>\n      <td>better</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ndf_data[\"label\"] = le.fit_transform(df_data.sentiment)\nprint(le.classes_)","execution_count":8,"outputs":[{"output_type":"stream","text":"['negative' 'neutral' 'positive']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data.head()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"       textID                                               text  \\\n0  a3d0a7d5ad  Spent the entire morning in a meeting w/ a ven...   \n1  251b6a6766      Oh! Good idea about putting them on ice cream   \n2  c9e8d1ef1c  says good (or should i say bad?) afternoon!  h...   \n3  f14f087215         i dont think you can vote anymore! i tried   \n4  bf7473b12d             haha better drunken tweeting you mean?   \n\n                                 selected_text sentiment  label  \n0  my boss was not happy w/ them. Lots of fun.   neutral      1  \n1                                         Good  positive      2  \n2  says good (or should i say bad?) afternoon!   neutral      1  \n3           i dont think you can vote anymore!  negative      0  \n4                                       better  positive      2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a3d0a7d5ad</td>\n      <td>Spent the entire morning in a meeting w/ a ven...</td>\n      <td>my boss was not happy w/ them. Lots of fun.</td>\n      <td>neutral</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>251b6a6766</td>\n      <td>Oh! Good idea about putting them on ice cream</td>\n      <td>Good</td>\n      <td>positive</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c9e8d1ef1c</td>\n      <td>says good (or should i say bad?) afternoon!  h...</td>\n      <td>says good (or should i say bad?) afternoon!</td>\n      <td>neutral</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>f14f087215</td>\n      <td>i dont think you can vote anymore! i tried</td>\n      <td>i dont think you can vote anymore!</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bf7473b12d</td>\n      <td>haha better drunken tweeting you mean?</td>\n      <td>better</td>\n      <td>positive</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_train, df_dev = train_test_split(df_data, test_size=0.2, random_state=42)\nprint(df_data.shape, df_train.shape, df_dev.shape)","execution_count":10,"outputs":[{"output_type":"stream","text":"(27485, 5) (21988, 5) (5497, 5)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = df_train[\"label\"]\ny_dev = df_dev[\"label\"]","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(stop_words='english')\nX_train = vectorizer.fit_transform(df_train[\"selected_text\"])\nX_dev = vectorizer.transform(df_dev[\"selected_text\"])\n\nprint(vectorizer.get_feature_names()[:10])\nprint(X_train.shape, X_dev.shape)\nprint(y_train.shape, y_dev.shape)","execution_count":12,"outputs":[{"output_type":"stream","text":"['00', '000', '007', '01', '02', '03', '04', '05', '06', '060']\n(21988, 15142) (5497, 15142)\n(21988,) (5497,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nmax_fatures = 2000\ntokenizer = Tokenizer(num_words=max_fatures, split=' ')\ntokenizer.fit_on_texts(df_train[\"selected_text\"])\nX_train_tokenized = tokenizer.texts_to_sequences(df_train[\"selected_text\"])\nX_train = pad_sequences(X_train_tokenized)\nprint(X_train.shape)","execution_count":56,"outputs":[{"output_type":"stream","text":"(21988, 31)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom keras.utils import np_utils\nfrom keras import regularizers","execution_count":13,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def baseline_lstm_model():\n    embed_dim = 128\n    lstm_out = 196\n\n    model = Sequential()\n    model.add(Embedding(max_fatures, embed_dim, input_length = X_train.shape[1]))\n    model.add(SpatialDropout1D(0.4))\n    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n    model.add(Dense(3,activation='softmax'))\n    model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics = ['sparse_categorical_accuracy'])\n    print(model.summary())\n    return model","execution_count":87,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nmodel = baseline_lstm_model()\nmodel.fit(X_train, y_train, epochs=7, batch_size=batch_size)","execution_count":88,"outputs":[{"output_type":"stream","text":"Model: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_6 (Embedding)      (None, 31, 128)           256000    \n_________________________________________________________________\nspatial_dropout1d_6 (Spatial (None, 31, 128)           0         \n_________________________________________________________________\nlstm_6 (LSTM)                (None, 196)               254800    \n_________________________________________________________________\ndense_5 (Dense)              (None, 3)                 591       \n=================================================================\nTotal params: 511,391\nTrainable params: 511,391\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","name":"stderr"},{"output_type":"stream","text":"Epoch 1/7\n21988/21988 [==============================] - 45s 2ms/step - loss: 0.6046 - sparse_categorical_accuracy: 0.7479\nEpoch 2/7\n21988/21988 [==============================] - 45s 2ms/step - loss: 0.4407 - sparse_categorical_accuracy: 0.8257\nEpoch 3/7\n21988/21988 [==============================] - 44s 2ms/step - loss: 0.4011 - sparse_categorical_accuracy: 0.8424\nEpoch 4/7\n21988/21988 [==============================] - 44s 2ms/step - loss: 0.3840 - sparse_categorical_accuracy: 0.8513\nEpoch 5/7\n21988/21988 [==============================] - 44s 2ms/step - loss: 0.3663 - sparse_categorical_accuracy: 0.8555\nEpoch 6/7\n21988/21988 [==============================] - 45s 2ms/step - loss: 0.3487 - sparse_categorical_accuracy: 0.8634\nEpoch 7/7\n21988/21988 [==============================] - 45s 2ms/step - loss: 0.3306 - sparse_categorical_accuracy: 0.8713\n","name":"stdout"},{"output_type":"execute_result","execution_count":88,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f1fa5a22898>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_to_sequence(df_column):\n    X_tokenized = tokenizer.texts_to_sequences(df_column.values)\n    X = pad_sequences(X_tokenized, maxlen=X_train.shape[1], dtype='int32', value=0)\n    return X\n\nX_dev = text_to_sequence(df_dev[\"selected_text\"])\nprint(X_dev.shape)","execution_count":89,"outputs":[{"output_type":"stream","text":"(5497, 31)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_dev, y_dev, batch_size=32)\nprint(score)","execution_count":91,"outputs":[{"output_type":"stream","text":"5497/5497 [==============================] - 3s 572us/step\n[0.4588489729923965, 0.8259050250053406]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dev.head()","execution_count":92,"outputs":[{"output_type":"execute_result","execution_count":92,"data":{"text/plain":"           textID                                               text  \\\n7534   f07cf90a98  is missing out on the sunshine and trying to s...   \n2664   95ce0e14ce   - i sure hope so  it was worth it for me too ...   \n12943  80775bf0e3  http://twitpic.com/4jccd - and also these hi t...   \n23884  60ce7c4890   The little weeping nervous girl was put throu...   \n4104   cc1af9564d  maybe someday. i lova ya, friends!! my compute...   \n\n                                           selected_text sentiment  label  \\\n7534   is missing out on the sunshine and trying to s...   neutral      1   \n2664   - i sure hope so  it was worth it for me too  ...  positive      2   \n12943  http://twitpic.com/4jccd - and also these hi t...   neutral      1   \n23884  The little weeping nervous girl was put throug...   neutral      1   \n4104   maybe someday. i lova ya, friends!! my compute...   neutral      1   \n\n       number_of_words_in_text  \n7534                        17  \n2664                        13  \n12943                       11  \n23884                       24  \n4104                        16  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>label</th>\n      <th>number_of_words_in_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7534</th>\n      <td>f07cf90a98</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>neutral</td>\n      <td>1</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>2664</th>\n      <td>95ce0e14ce</td>\n      <td>- i sure hope so  it was worth it for me too ...</td>\n      <td>- i sure hope so  it was worth it for me too  ...</td>\n      <td>positive</td>\n      <td>2</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>12943</th>\n      <td>80775bf0e3</td>\n      <td>http://twitpic.com/4jccd - and also these hi t...</td>\n      <td>http://twitpic.com/4jccd - and also these hi t...</td>\n      <td>neutral</td>\n      <td>1</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>23884</th>\n      <td>60ce7c4890</td>\n      <td>The little weeping nervous girl was put throu...</td>\n      <td>The little weeping nervous girl was put throug...</td>\n      <td>neutral</td>\n      <td>1</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>4104</th>\n      <td>cc1af9564d</td>\n      <td>maybe someday. i lova ya, friends!! my compute...</td>\n      <td>maybe someday. i lova ya, friends!! my compute...</td>\n      <td>neutral</td>\n      <td>1</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dev[\"number_of_words_in_text\"] = df_dev.text.str.split().str.len()","execution_count":93,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    df_ngrams = pd.read_pickle(\"df_ngrams.pkl\")\nexcept:\n    df_ngrams = pd.DataFrame()\n    for i in range(df_dev[\"text\"].shape[0]):\n        if i%1000==0:\n            print(i)\n        try:\n            vectorizer_tmp = TfidfVectorizer(ngram_range=(1,df_dev.iloc[i][\"number_of_words_in_text\"]),token_pattern=r'\\S+')\n            ngrams = vectorizer_tmp.fit([df_dev.iloc[i][\"text\"]]).get_feature_names()\n            df_tmp = pd.DataFrame({\n                \"textID\":df_dev.iloc[i][\"textID\"],\n                \"selected_text\":df_dev.iloc[i][\"selected_text\"],\n                \"selected_text_predict\":ngrams,\n                \"label\":df_dev.iloc[i][\"label\"]\n            })\n            df_ngrams = pd.concat([df_ngrams,df_tmp])\n        except Exception as e:\n            print(\"problem with \", i)\n            pass\n\n    #           print(e)\n    df_ngrams.to_pickle(\"df_ngrams.pkl\")\ndf_ngrams.shape","execution_count":97,"outputs":[{"output_type":"execute_result","execution_count":97,"data":{"text/plain":"(615874, 4)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_to_predict = text_to_sequence(df_ngrams[\"selected_text_predict\"])\ny_pred = model.predict(X_to_predict, verbose=1)\ny_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ngrams[\"pred1\"] = y_pred[:,0]\ndf_ngrams[\"pred2\"] = y_pred[:,1]\ndf_ngrams[\"pred3\"] = y_pred[:,2]","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ngrams.loc[df_ngrams.label==0,\"final_pred\"] = df_ngrams.loc[df_ngrams.label==0,\"pred1\"] \ndf_ngrams.loc[df_ngrams.label==1,\"final_pred\"] = df_ngrams.loc[df_ngrams.label==1,\"pred2\"] \ndf_ngrams.loc[df_ngrams.label==2,\"final_pred\"] = df_ngrams.loc[df_ngrams.label==2,\"pred3\"] ","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ngrams.head(10)","execution_count":73,"outputs":[{"output_type":"execute_result","execution_count":73,"data":{"text/plain":"       textID                                      selected_text  \\\n0  f07cf90a98  is missing out on the sunshine and trying to s...   \n1  f07cf90a98  is missing out on the sunshine and trying to s...   \n2  f07cf90a98  is missing out on the sunshine and trying to s...   \n3  f07cf90a98  is missing out on the sunshine and trying to s...   \n4  f07cf90a98  is missing out on the sunshine and trying to s...   \n5  f07cf90a98  is missing out on the sunshine and trying to s...   \n6  f07cf90a98  is missing out on the sunshine and trying to s...   \n7  f07cf90a98  is missing out on the sunshine and trying to s...   \n8  f07cf90a98  is missing out on the sunshine and trying to s...   \n9  f07cf90a98  is missing out on the sunshine and trying to s...   \n\n             selected_text_predict  label     pred1     pred2     pred3  \\\n0                                2      1  0.159693  0.343380  0.496927   \n1                          2 hours      1  0.086613  0.889480  0.023908   \n2                    2 hours sleep      1  0.073678  0.894130  0.032192   \n3                            after      1  0.076633  0.376148  0.547218   \n4                     after having      1  0.155563  0.338103  0.506333   \n5                after having just      1  0.136050  0.544204  0.319746   \n6              after having just 2      1  0.047231  0.724387  0.228382   \n7        after having just 2 hours      1  0.021542  0.959485  0.018973   \n8  after having just 2 hours sleep      1  0.030434  0.941097  0.028470   \n9                              and      1  0.271775  0.319666  0.408559   \n\n   final_pred  \n0    0.343380  \n1    0.889480  \n2    0.894130  \n3    0.376148  \n4    0.338103  \n5    0.544204  \n6    0.724387  \n7    0.959485  \n8    0.941097  \n9    0.319666  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>selected_text</th>\n      <th>selected_text_predict</th>\n      <th>label</th>\n      <th>pred1</th>\n      <th>pred2</th>\n      <th>pred3</th>\n      <th>final_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f07cf90a98</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.159693</td>\n      <td>0.343380</td>\n      <td>0.496927</td>\n      <td>0.343380</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f07cf90a98</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>2 hours</td>\n      <td>1</td>\n      <td>0.086613</td>\n      <td>0.889480</td>\n      <td>0.023908</td>\n      <td>0.889480</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>f07cf90a98</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>2 hours sleep</td>\n      <td>1</td>\n      <td>0.073678</td>\n      <td>0.894130</td>\n      <td>0.032192</td>\n      <td>0.894130</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>f07cf90a98</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>after</td>\n      <td>1</td>\n      <td>0.076633</td>\n      <td>0.376148</td>\n      <td>0.547218</td>\n      <td>0.376148</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>f07cf90a98</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>after having</td>\n      <td>1</td>\n      <td>0.155563</td>\n      <td>0.338103</td>\n      <td>0.506333</td>\n      <td>0.338103</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>f07cf90a98</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>after having just</td>\n      <td>1</td>\n      <td>0.136050</td>\n      <td>0.544204</td>\n      <td>0.319746</td>\n      <td>0.544204</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>f07cf90a98</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>after having just 2</td>\n      <td>1</td>\n      <td>0.047231</td>\n      <td>0.724387</td>\n      <td>0.228382</td>\n      <td>0.724387</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>f07cf90a98</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>after having just 2 hours</td>\n      <td>1</td>\n      <td>0.021542</td>\n      <td>0.959485</td>\n      <td>0.018973</td>\n      <td>0.959485</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>f07cf90a98</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>after having just 2 hours sleep</td>\n      <td>1</td>\n      <td>0.030434</td>\n      <td>0.941097</td>\n      <td>0.028470</td>\n      <td>0.941097</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>f07cf90a98</td>\n      <td>is missing out on the sunshine and trying to s...</td>\n      <td>and</td>\n      <td>1</td>\n      <td>0.271775</td>\n      <td>0.319666</td>\n      <td>0.408559</td>\n      <td>0.319666</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ngrams[\"len_selected_text_predict\"] = df_ngrams.selected_text_predict.str.len()\ndf_ngrams.sort_values(by=['len_selected_text_predict'], ascending=False, inplace=True)","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = df_ngrams.groupby(['textID'])['final_pred'].transform(max) == df_ngrams['final_pred']","execution_count":75,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dev_final = df_ngrams[idx].drop_duplicates(subset='textID', keep=\"first\")","execution_count":76,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dev_enriched = pd.merge(df_dev, df_dev_final[[\"textID\",\"selected_text_predict\"]], on='textID', how='left')","execution_count":77,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dev_enriched.loc[df_dev_enriched.selected_text_predict.isnull(),\"selected_text_predict\"] = df_dev_enriched.loc[df_dev_enriched.selected_text_predict.isnull(),\"text\"] ","execution_count":78,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 58% is the accuracy when selected text is equal to text!! ","execution_count":79,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(strs): \n    str1=strs['selected_text']\n    str2=strs['selected_text_predict']\n    \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":80,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dev_enriched['jaccard']=df_dev_enriched[['selected_text','selected_text_predict']].apply(lambda x: jaccard(x),axis=1)\n\nprint(f\"Average jaccard index in training data {df_dev_enriched['jaccard'].mean()}\")\ndf_dev_enriched['jaccard'].hist(bins=30)","execution_count":81,"outputs":[{"output_type":"stream","text":"Average jaccard index in training data 0.4840155022496218\n","name":"stdout"},{"output_type":"execute_result","execution_count":81,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f1fa5b50780>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dev_enriched_baseline = df_dev_enriched.copy()\ndf_dev_enriched_baseline[\"selected_text_predict\"]= df_dev_enriched_baseline[\"text\"]\ndf_dev_enriched_baseline['jaccard']=df_dev_enriched_baseline[['selected_text','selected_text_predict']].apply(lambda x: jaccard(x),axis=1)\nprint(f\"Average jaccard index in training data {df_dev_enriched_baseline['jaccard'].mean()}\")\ndf_dev_enriched_baseline['jaccard'].hist(bins=30)","execution_count":82,"outputs":[{"output_type":"stream","text":"Average jaccard index in training data 0.5878679493589238\n","name":"stdout"},{"output_type":"execute_result","execution_count":82,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f1fa5cd5240>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Good predictions\nprint(\"Good Predictions\\n__________\")\ndf_sample = df_dev_enriched[df_dev_enriched.jaccard > .9]\nfor i in range(10):\n    print(\"textID:    \", df_sample.iloc[i][\"textID\"])\n    print(\"sentiment: \", df_sample.iloc[i][\"sentiment\"])\n    print(\"original:  \", df_sample.iloc[i][\"text\"])\n    print(\"target:    \" , df_sample.iloc[i][\"selected_text\"])\n    print(\"prediction:\", df_sample.iloc[i][\"selected_text_predict\"])    \n    print(\"--\")\n    \n# Bad predictions\nprint(\"Bad Predictions\\n__________\")\ndf_sample = df_dev_enriched[df_dev_enriched.jaccard < .1]\nfor i in range(10):\n    print(\"textID:    \", df_sample.iloc[i][\"textID\"])\n    print(\"sentiment: \", df_sample.iloc[i][\"sentiment\"])\n    print(\"original:  \", df_sample.iloc[i][\"text\"])\n    print(\"target:    \" , df_sample.iloc[i][\"selected_text\"])\n    print(\"prediction:\", df_sample.iloc[i][\"selected_text_predict\"])    \n    print(\"--\")","execution_count":83,"outputs":[{"output_type":"stream","text":"Good Predictions\n__________\ntextID:     cc1af9564d\nsentiment:  neutral\noriginal:   maybe someday. i lova ya, friends!! my computer sucks  listening to coldplay&lt;3 tomorrow meet my bbff\ntarget:     maybe someday. i lova ya, friends!! my computer sucks  listening to coldplay&lt;3 tomorrow meet my bb\nprediction: maybe someday. i lova ya, friends!! my computer sucks listening to coldplay&lt;3 tomorrow meet\n--\ntextID:     b7ca4a54c2\nsentiment:  negative\noriginal:   home from work today.....son is sick\ntarget:     sick\nprediction: sick\n--\ntextID:     10c1f302a6\nsentiment:  neutral\noriginal:   Maybe going apartment shopping with Ashley?\ntarget:     Maybe going apartment shopping with Ashley?\nprediction: maybe going apartment shopping with ashley?\n--\ntextID:     c92b5a0bf7\nsentiment:  neutral\noriginal:    ahh seen a few of those drop, but I just tossed them thinking it was a once only turn in\ntarget:     ahh seen a few of those drop, but I just tossed them thinking it was a once only turn in\nprediction: ahh seen a few of those drop, but i just tossed them thinking it was a once only turn\n--\ntextID:     6ae7977873\nsentiment:  positive\noriginal:    so see you on my birthday visit me  haha why wack Saturday ?\ntarget:     haha\nprediction: haha\n--\ntextID:     275355d0ba\nsentiment:  positive\noriginal:   About to embark on a large tour of bars for a project.  Hopefully I won't die from alcohol poisoning\ntarget:     Hopefully\nprediction: hopefully\n--\ntextID:     3932877e2b\nsentiment:  negative\noriginal:    dammit i had the passes but i am still at work\ntarget:     dammit\nprediction: dammit\n--\ntextID:     fcbf31b293\nsentiment:  neutral\noriginal:   is clamped out...haha\ntarget:     is clamped out...haha\nprediction: is clamped out...haha\n--\ntextID:     8b9ad8f948\nsentiment:  positive\noriginal:   ofcourse they start fightin aight the party buts its cool theyu held it down now im chillin with my home girl  HAPPY MOTHERS DAY\ntarget:     HAPPY\nprediction: happy\n--\ntextID:     4e7f6f6e25\nsentiment:  neutral\noriginal:   Watching boxing and waiting to go out to Hollywood tonight\ntarget:     Watching boxing and waiting to go out to Hollywood tonight\nprediction: watching boxing and waiting to go out to hollywood tonight\n--\nBad Predictions\n__________\ntextID:     95ce0e14ce\nsentiment:  positive\noriginal:    - i sure hope so  it was worth it for me too  loveu.\ntarget:     - i sure hope so  it was worth it for me too  loveu.\nprediction: worth\n--\ntextID:     1968e10eb5\nsentiment:  positive\noriginal:   seniors done  5 more days!! woohoo!! going out for the night.\ntarget:     woohoo!\nprediction: woohoo!!\n--\ntextID:     89b6e4feb0\nsentiment:  negative\noriginal:   I'm feeling so frustrated...I just can't get things to work!!\ntarget:     I'm feeling so frustrated..\nprediction: frustrated...i\n--\ntextID:     420ad91e31\nsentiment:  positive\noriginal:   great night hangin out with my family... mom and dad loved the extra company tonight!  can't wait for FRC Pcola Tomorrow\ntarget:     great night hangin out with my family... mom and dad loved the extra company tonight!\nprediction: loved\n--\ntextID:     762e9f81f7\nsentiment:  positive\noriginal:    My original non-Yahoo acc. was deleted when they got bought-out  But it's not too bad, I don't receive any Yahoo-spam from it.\ntarget:     s not too bad\nprediction: acc. was\n--\ntextID:     6dba3a987e\nsentiment:  negative\noriginal:   Hav fun at heav y Metal happy hour you guys! In the future  accadentally sets it on fire while smoking with \ntarget:     accadentally\nprediction: heav y metal\n--\ntextID:     fee94735e2\nsentiment:  neutral\noriginal:   It turns out I'm really, like, sixty years old, guys. You were right!!!!!  I'm off to seek my future a little later than planned!\ntarget:     It turns out I'm really, like, sixty years old, guys. You were right!!!!!  I'm off to seek my future a little later than planned!\nprediction: it turns\n--\ntextID:     1484dd2416\nsentiment:  positive\noriginal:   yum - mother's day lunch at The Food Business in Burnside was delicious! such a gorgeous day\ntarget:     delicious! such a gorgeous day\nprediction: yum - mother's\n--\ntextID:     109c3ddb5f\nsentiment:  negative\noriginal:    When oh when are you coming back for a gig in Scotland? I had tickets to see u last year but was in hosp wit gallstones!\ntarget:     but was in hosp\nprediction: gig\n--\ntextID:     0d1a051f0a\nsentiment:  negative\noriginal:   I'm pondering lunch at Shane's. I think. I can already hear people whining about it...\ntarget:     whining ab\nprediction: hear\n--\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ngrams[df_ngrams.textID == \"3e9e3f0d69\"]","execution_count":84,"outputs":[{"output_type":"execute_result","execution_count":84,"data":{"text/plain":"        textID                        selected_text  \\\n15  3e9e3f0d69  you're just altered forever   Enjoy   \n20  3e9e3f0d69  you're just altered forever   Enjoy   \n14  3e9e3f0d69  you're just altered forever   Enjoy   \n19  3e9e3f0d69  you're just altered forever   Enjoy   \n9   3e9e3f0d69  you're just altered forever   Enjoy   \n13  3e9e3f0d69  you're just altered forever   Enjoy   \n2   3e9e3f0d69  you're just altered forever   Enjoy   \n8   3e9e3f0d69  you're just altered forever   Enjoy   \n18  3e9e3f0d69  you're just altered forever   Enjoy   \n12  3e9e3f0d69  you're just altered forever   Enjoy   \n1   3e9e3f0d69  you're just altered forever   Enjoy   \n5   3e9e3f0d69  you're just altered forever   Enjoy   \n7   3e9e3f0d69  you're just altered forever   Enjoy   \n11  3e9e3f0d69  you're just altered forever   Enjoy   \n17  3e9e3f0d69  you're just altered forever   Enjoy   \n0   3e9e3f0d69  you're just altered forever   Enjoy   \n4   3e9e3f0d69  you're just altered forever   Enjoy   \n16  3e9e3f0d69  you're just altered forever   Enjoy   \n3   3e9e3f0d69  you're just altered forever   Enjoy   \n10  3e9e3f0d69  you're just altered forever   Enjoy   \n6   3e9e3f0d69  you're just altered forever   Enjoy   \n\n                      selected_text_predict  label     pred1     pred2  \\\n15  nah, you're just altered forever enjoy.      2  0.029375  0.023872   \n20       you're just altered forever enjoy.      2  0.016366  0.008147   \n14         nah, you're just altered forever      2  0.265671  0.609038   \n19              you're just altered forever      2  0.393168  0.397285   \n9               just altered forever enjoy.      2  0.025442  0.003759   \n13                 nah, you're just altered      2  0.089813  0.749649   \n2                    altered forever enjoy.      2  0.014485  0.001399   \n8                      just altered forever      2  0.742053  0.152044   \n18                      you're just altered      2  0.109926  0.434708   \n12                         nah, you're just      2  0.089813  0.749649   \n1                           altered forever      2  0.864781  0.045743   \n5                            forever enjoy.      2  0.014485  0.001399   \n7                              just altered      2  0.405318  0.254300   \n11                              nah, you're      2  0.108652  0.633616   \n17                              you're just      2  0.109926  0.434708   \n0                                   altered      2  0.600628  0.061387   \n4                                   forever      2  0.864781  0.045743   \n16                                   you're      2  0.082870  0.183146   \n3                                    enjoy.      2  0.001968  0.000630   \n10                                     nah,      2  0.362571  0.455645   \n6                                      just      2  0.405318  0.254300   \n\n       pred3  final_pred  len_selected_text_predict  \n15  0.946753    0.946753                         39  \n20  0.975486    0.975486                         34  \n14  0.125292    0.125292                         32  \n19  0.209547    0.209547                         27  \n9   0.970799    0.970799                         27  \n13  0.160538    0.160538                         24  \n2   0.984116    0.984116                         22  \n8   0.105903    0.105903                         20  \n18  0.455366    0.455366                         19  \n12  0.160538    0.160538                         16  \n1   0.089476    0.089476                         15  \n5   0.984116    0.984116                         14  \n7   0.340382    0.340382                         12  \n11  0.257732    0.257732                         11  \n17  0.455366    0.455366                         11  \n0   0.337985    0.337985                          7  \n4   0.089476    0.089476                          7  \n16  0.733984    0.733984                          6  \n3   0.997402    0.997402                          6  \n10  0.181784    0.181784                          4  \n6   0.340382    0.340382                          4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>selected_text</th>\n      <th>selected_text_predict</th>\n      <th>label</th>\n      <th>pred1</th>\n      <th>pred2</th>\n      <th>pred3</th>\n      <th>final_pred</th>\n      <th>len_selected_text_predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>nah, you're just altered forever enjoy.</td>\n      <td>2</td>\n      <td>0.029375</td>\n      <td>0.023872</td>\n      <td>0.946753</td>\n      <td>0.946753</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>you're just altered forever enjoy.</td>\n      <td>2</td>\n      <td>0.016366</td>\n      <td>0.008147</td>\n      <td>0.975486</td>\n      <td>0.975486</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>nah, you're just altered forever</td>\n      <td>2</td>\n      <td>0.265671</td>\n      <td>0.609038</td>\n      <td>0.125292</td>\n      <td>0.125292</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>you're just altered forever</td>\n      <td>2</td>\n      <td>0.393168</td>\n      <td>0.397285</td>\n      <td>0.209547</td>\n      <td>0.209547</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>just altered forever enjoy.</td>\n      <td>2</td>\n      <td>0.025442</td>\n      <td>0.003759</td>\n      <td>0.970799</td>\n      <td>0.970799</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>nah, you're just altered</td>\n      <td>2</td>\n      <td>0.089813</td>\n      <td>0.749649</td>\n      <td>0.160538</td>\n      <td>0.160538</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>altered forever enjoy.</td>\n      <td>2</td>\n      <td>0.014485</td>\n      <td>0.001399</td>\n      <td>0.984116</td>\n      <td>0.984116</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>just altered forever</td>\n      <td>2</td>\n      <td>0.742053</td>\n      <td>0.152044</td>\n      <td>0.105903</td>\n      <td>0.105903</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>you're just altered</td>\n      <td>2</td>\n      <td>0.109926</td>\n      <td>0.434708</td>\n      <td>0.455366</td>\n      <td>0.455366</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>nah, you're just</td>\n      <td>2</td>\n      <td>0.089813</td>\n      <td>0.749649</td>\n      <td>0.160538</td>\n      <td>0.160538</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>altered forever</td>\n      <td>2</td>\n      <td>0.864781</td>\n      <td>0.045743</td>\n      <td>0.089476</td>\n      <td>0.089476</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>forever enjoy.</td>\n      <td>2</td>\n      <td>0.014485</td>\n      <td>0.001399</td>\n      <td>0.984116</td>\n      <td>0.984116</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>just altered</td>\n      <td>2</td>\n      <td>0.405318</td>\n      <td>0.254300</td>\n      <td>0.340382</td>\n      <td>0.340382</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>nah, you're</td>\n      <td>2</td>\n      <td>0.108652</td>\n      <td>0.633616</td>\n      <td>0.257732</td>\n      <td>0.257732</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>you're just</td>\n      <td>2</td>\n      <td>0.109926</td>\n      <td>0.434708</td>\n      <td>0.455366</td>\n      <td>0.455366</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>altered</td>\n      <td>2</td>\n      <td>0.600628</td>\n      <td>0.061387</td>\n      <td>0.337985</td>\n      <td>0.337985</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>forever</td>\n      <td>2</td>\n      <td>0.864781</td>\n      <td>0.045743</td>\n      <td>0.089476</td>\n      <td>0.089476</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>you're</td>\n      <td>2</td>\n      <td>0.082870</td>\n      <td>0.183146</td>\n      <td>0.733984</td>\n      <td>0.733984</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>enjoy.</td>\n      <td>2</td>\n      <td>0.001968</td>\n      <td>0.000630</td>\n      <td>0.997402</td>\n      <td>0.997402</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>nah,</td>\n      <td>2</td>\n      <td>0.362571</td>\n      <td>0.455645</td>\n      <td>0.181784</td>\n      <td>0.181784</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3e9e3f0d69</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>just</td>\n      <td>2</td>\n      <td>0.405318</td>\n      <td>0.254300</td>\n      <td>0.340382</td>\n      <td>0.340382</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dev_enriched[df_dev_enriched.textID == \"3e9e3f0d69\"]","execution_count":85,"outputs":[{"output_type":"execute_result","execution_count":85,"data":{"text/plain":"        textID                                        text  \\\n65  3e9e3f0d69   nah, you're just altered forever   Enjoy.   \n\n                          selected_text sentiment  label  \\\n65  you're just altered forever   Enjoy  positive      2   \n\n    number_of_words_in_text selected_text_predict  jaccard  \n65                        6                enjoy.      0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>label</th>\n      <th>number_of_words_in_text</th>\n      <th>selected_text_predict</th>\n      <th>jaccard</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>65</th>\n      <td>3e9e3f0d69</td>\n      <td>nah, you're just altered forever   Enjoy.</td>\n      <td>you're just altered forever   Enjoy</td>\n      <td>positive</td>\n      <td>2</td>\n      <td>6</td>\n      <td>enjoy.</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
